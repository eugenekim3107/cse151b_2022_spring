{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e181feba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961d7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"./argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        inputs, outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        comb = np.concatenate((inputs, outputs), axis = 1).T\n",
    "        test = np.tile(comb,60).T\n",
    "        final = np.empty((0,51,2))\n",
    "        for i in range(60):\n",
    "            final = np.concatenate((final,test[0:inputs.shape[0],i:51+i,:]))\n",
    "        final = np.hsplit(final, [50])\n",
    "        self.inputs = final[0]\n",
    "        self.outputs = final[1]\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "pa = 'palo-alto' \n",
    "# au = 'austin'\n",
    "# mi = 'miami'\n",
    "# pi = 'pittsburgh'\n",
    "# db = 'dearborn'\n",
    "# dc = 'washington-dc'\n",
    "split = 'train'\n",
    "train_dataset_pa = ArgoverseDataset(city = pa, split = split)\n",
    "# train_dataset_au = ArgoverseDataset(city = au, split = split)\n",
    "# train_dataset_pi = ArgoverseDataset(city = pi, split = split)\n",
    "# train_dataset_db = ArgoverseDataset(city = db, split = split)\n",
    "# train_dataset_dc = ArgoverseDataset(city = dc, split = split)\n",
    "# train_dataset_mi = ArgoverseDataset(city = mi, split = split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6775c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = len(train_dataset_pa)\n",
    "train_loader_pa = DataLoader(train_dataset_pa,batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9831c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batch in enumerate(train_loader_pa):\n",
    "    inp, out = sample_batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341233d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
